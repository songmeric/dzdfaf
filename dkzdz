#!/usr/bin/env python3
"""
latency-portal  ◆  nano-latency visualiser
• Added earlier: un-approve endpoint, ISO-date x-axes, tooltip-ready stats.
• Now: baseline comparison (server-rendered dropdown & auto-select), CDF plot,
       robust stats (p99.9, MADn, IQR, outlier rate) + compare deltas table.
"""

import base64, io, json, logging, pathlib, sqlite3, statistics, datetime as dt
from typing import List, Tuple, Optional, Dict
import pandas as pd
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt
from fastapi import FastAPI, Request, HTTPException, Form
from fastapi.responses import HTMLResponse, RedirectResponse, PlainTextResponse
from fastapi.templating import Jinja2Templates

CSV_DIR = pathlib.Path("/apps/sp_hfts/latency_csv"); CSV_DIR.mkdir(parents=True, exist_ok=True)
BASE_DIR = pathlib.Path(__file__).parent
LOG_FILE = BASE_DIR / "portal.log"
DB_PATH  = str(CSV_DIR / "runs.db")                     # ensure str
TPL_DIR  = BASE_DIR / "templates"

logging.basicConfig(level=logging.INFO,
                    format="%(asctime)s  %(levelname)-8s %(message)s",
                    handlers=[logging.FileHandler(LOG_FILE, encoding="utf-8"),
                              logging.StreamHandler()])
log = logging.getLogger("latency-portal")

app       = FastAPI(title="Latency-Portal")
templates = Jinja2Templates(directory=str(TPL_DIR))

# ─── DB ───────────────────────────────────────────────────────────────────────
def _init_db() -> None:
    with sqlite3.connect(DB_PATH) as c:
        c.execute("""CREATE TABLE IF NOT EXISTS runs(
            id          TEXT PRIMARY KEY,
            filename    TEXT,
            created_at  TEXT,
            p50         REAL, p95 REAL, p99 REAL,
            stdev       REAL, count INTEGER,
            approved    INTEGER DEFAULT 0,
            approved_by TEXT, approved_at TEXT,
            png_b64     TEXT );""")
_init_db()

def _row_to_dict(row) -> dict:
    keys=("id","filename","created_at","p50","p95","p99","stdev","count",
          "approved","approved_by","approved_at","png_b64")
    return dict(zip(keys,row))

# ─── CSV ingestion (unchanged) ───────────────────────────────────────────────
def _ingest_new_files() -> None:
    with sqlite3.connect(DB_PATH) as c:
        known = {r[0] for r in c.execute("SELECT id FROM runs")}
    for csv_path in CSV_DIR.glob("*.csv"):
        run_id = csv_path.stem
        if run_id in known: continue
        try:
            df = pd.read_csv(csv_path, skipinitialspace=True,
                    names=["entry_id","ingress","egress","latency_ns"],
                    header=0, dtype={"ingress":"int64","latency_ns":"int64"},
                    engine="python")
        except Exception as exc:
            log.error("Failed to parse %s: %s", csv_path.name, exc); continue
        if df.empty: log.error("Empty CSV %s", csv_path.name); continue
        df.sort_values("ingress", inplace=True)
        lat = df["latency_ns"]
        p50,p95,p99 = (lat.quantile(q) for q in (0.5,0.95,0.99))
        stdev = statistics.pstdev(lat)
        fig, ax = plt.subplots(); ax.plot(df["ingress"], lat, linewidth=0.5)
        ax.set_xlabel("Ingress ns"); ax.set_ylabel("Latency ns"); ax.set_title(run_id)
        buf = io.BytesIO(); fig.savefig(buf, format="png", dpi=110, bbox_inches="tight")
        plt.close(fig); png_b64 = base64.b64encode(buf.getvalue()).decode()
        with sqlite3.connect(DB_PATH) as c:
            c.execute("INSERT INTO runs VALUES (?,?,?,?,?,?,?,?,?,?,?,?)",
                      (run_id, csv_path.name, dt.datetime.utcnow().isoformat(),
                       p50,p95,p99,stdev,len(lat),0,None,None,png_b64))
        log.info("Ingested %s", csv_path.name)

@app.middleware("http")
async def auto_ingest(request: Request, call_next):
    _ingest_new_files(); return await call_next(request)

# ─── Helpers ─────────────────────────────────────────────────────────────────
def _per_second_quantiles(df) -> Tuple[List[str], List[float], List[float], List[float]]:
    df["sec"] = (df["ingress"] // 1_000_000_000)
    grouped   = df.groupby("sec")["latency_ns"]
    p50 = grouped.quantile(0.50); p95 = grouped.quantile(0.95); p99 = grouped.quantile(0.99)
    idx_iso = pd.to_datetime(p50.index.astype("int64"), unit="s", utc=True)\
                 .strftime("%Y-%m-%dT%H:%M:%SZ").tolist()
    return idx_iso, p50.tolist(), p95.tolist(), p99.tolist()

def _load_run_meta(run_id: str) -> dict:
    with sqlite3.connect(DB_PATH) as c:
        row = c.execute("SELECT * FROM runs WHERE id=?", (run_id,)).fetchone()
    if not row:
        raise HTTPException(404, "run not found")
    return _row_to_dict(row)

def _load_run_df_by_meta(meta: dict) -> pd.DataFrame:
    csv_path = CSV_DIR / meta["filename"]
    if not csv_path.exists():
        raise HTTPException(500, "CSV missing")
    df = pd.read_csv(csv_path, skipinitialspace=True,
        names=["entry_id","ingress","egress","latency_ns"], header=0,
        dtype={"ingress":"int64","latency_ns":"int64"}, engine="python"
    ).sort_values("ingress")
    return df

def _summary_stats(lat: pd.Series) -> Dict[str, float]:
    lat = pd.to_numeric(lat, errors="coerce").dropna()
    if lat.empty:
        return {}
    q = lat.quantile([0.5, 0.95, 0.99, 0.999])
    median = float(q.loc[0.5])
    mad = float((lat - median).abs().median())
    madn = float(1.4826 * mad) if mad > 0 else 0.0   # ≈ σ for normal
    iqr  = float(lat.quantile(0.75) - lat.quantile(0.25))
    mean = float(lat.mean())
    stdev = float(statistics.pstdev(lat))
    denom = madn if madn > 0 else 1.0
    robust_z = ((lat - median).abs() / denom)
    outlier_rate = float((robust_z > 3.5).mean())
    return {
        "p50": float(q.loc[0.5]),
        "p95": float(q.loc[0.95]),
        "p99": float(q.loc[0.99]),
        "p999": float(q.loc[0.999]),
        "mean": mean,
        "stdev": stdev,
        "madn": madn,
        "iqr": iqr,
        "min": float(lat.min()),
        "max": float(lat.max()),
        "count": int(lat.size),
        "outlier_rate": outlier_rate,
    }

def _find_default_baseline_id(current_id: str) -> Optional[str]:
    with sqlite3.connect(DB_PATH) as c:
        row = c.execute("SELECT created_at FROM runs WHERE id=?", (current_id,)).fetchone()
        if not row:
            return None
        created_at = row[0]
        r = c.execute("""SELECT id FROM runs
                         WHERE approved=1 AND created_at < ?
                         ORDER BY created_at DESC LIMIT 1""", (created_at,)).fetchone()
        if r:
            return r[0]
        r = c.execute("""SELECT id FROM runs
                         WHERE created_at < ?
                         ORDER BY created_at DESC LIMIT 1""", (created_at,)).fetchone()
        return r[0] if r else None

def _baseline_candidates(current_created_at: str, limit:int=100) -> List[dict]:
    """All earlier runs to populate the dropdown (server-rendered)."""
    with sqlite3.connect(DB_PATH) as c:
        rows = c.execute(
            """SELECT id,created_at,approved,p50,p95,p99,stdev,count
               FROM runs
               WHERE created_at < ?
               ORDER BY created_at DESC
               LIMIT ?""",
            (current_created_at, int(limit))
        ).fetchall()
    keys=("id","created_at","approved","p50","p95","p99","stdev","count")
    return [dict(zip(keys,r)) for r in rows]

# ─── Routes ──────────────────────────────────────────────────────────────────
@app.get("/", response_class=HTMLResponse)
def list_runs(request: Request):
    with sqlite3.connect(DB_PATH) as c:
        rows=c.execute("SELECT * FROM runs ORDER BY created_at DESC").fetchall()
    return templates.TemplateResponse("list.html", {"request":request,"runs":[_row_to_dict(r) for r in rows]})

@app.get("/approved", response_class=HTMLResponse)
def approved(request: Request):
    with sqlite3.connect(DB_PATH) as c:
        rows=c.execute("SELECT * FROM runs WHERE approved=1 ORDER BY created_at DESC").fetchall()
    return templates.TemplateResponse("list.html", {"request":request,"runs":[_row_to_dict(r) for r in rows]})

@app.get("/runs/latest")
def latest_redirect():
    with sqlite3.connect(DB_PATH) as c:
        row=c.execute("SELECT id FROM runs ORDER BY created_at DESC LIMIT 1").fetchone()
    if not row: raise HTTPException(404,"No runs")
    return RedirectResponse(f"/runs/{row[0]}", status_code=303)

@app.get("/runs/{run_id}", response_class=HTMLResponse)
def show_run(request: Request, run_id:str):
    with sqlite3.connect(DB_PATH) as c:
        row=c.execute("SELECT * FROM runs WHERE id=?", (run_id,)).fetchone()
    if not row: raise HTTPException(404)
    d=_row_to_dict(row)

    # Load CSV
    csv_path=CSV_DIR/d["filename"]
    if not csv_path.exists(): raise HTTPException(500,"CSV missing")
    df=pd.read_csv(csv_path, skipinitialspace=True,
        names=["entry_id","ingress","egress","latency_ns"], header=0,
        dtype={"ingress":"int64","latency_ns":"int64"}, engine="python").sort_values("ingress")
    df["ingress_dt"]=pd.to_datetime(df["ingress"], unit="ns", utc=True)

    # Raw plot data
    x_json=json.dumps(df["ingress_dt"].dt.strftime("%Y-%m-%dT%H:%M:%S.%fZ").tolist())
    y_json=json.dumps(df["latency_ns"].tolist())

    # Per-second quantiles
    sec_iso,p50s,p95s,p99s=_per_second_quantiles(df)

    # Robust stats (current run)
    stats = _summary_stats(df["latency_ns"])

    # Current CDF (no numpy required)
    points = 300
    ps = [(i+1)/(points+1) for i in range(points)]
    qs = df["latency_ns"].quantile(ps).astype(float).tolist()

    # Baseline: default + candidates (server-rendered dropdown)
    baseline_default = _find_default_baseline_id(run_id) or ""
    baseline_runs    = _baseline_candidates(d["created_at"], limit=100)

    return templates.TemplateResponse("detail.html",
        {"request":request, **d,
         "x_json":x_json, "y_json":y_json,
         "sec_json":json.dumps(sec_iso),
         "p50_json":json.dumps(p50s),
         "p95_json":json.dumps(p95s),
         "p99_json":json.dumps(p99s),
         "baseline_default": baseline_default,
         "baseline_runs": baseline_runs,
         "stats_json": json.dumps(stats),
         "cdf_p_json": json.dumps(ps),
         "cdf_q_json": json.dumps(qs)})

@app.post("/runs/{run_id}/approve")
def approve(run_id:str, user:str=Form("anon")):
    now=dt.datetime.utcnow().isoformat()
    with sqlite3.connect(DB_PATH) as c:
        changed=c.execute("UPDATE runs SET approved=1,approved_by=?,approved_at=? WHERE id=? AND approved=0",
                          (user,now,run_id)).rowcount
    if changed==0: raise HTTPException(409,"already approved or missing")
    return RedirectResponse(f"/runs/{run_id}", status_code=303)

@app.post("/runs/{run_id}/unapprove")
def unapprove(run_id:str):
    with sqlite3.connect(DB_PATH) as c:
        changed=c.execute("UPDATE runs SET approved=0,approved_by=NULL,approved_at=NULL WHERE id=? AND approved=1",
                          (run_id,)).rowcount
    if changed==0: raise HTTPException(409,"not approved or missing")
    return RedirectResponse(f"/runs/{run_id}", status_code=303)

@app.get("/runs/{run_id}/status")
def status(run_id:str):
    with sqlite3.connect(DB_PATH) as c:
        row=c.execute("SELECT approved FROM runs WHERE id=?", (run_id,)).fetchone()
    if not row: raise HTTPException(404)
    return {"run_id":run_id,"approved":bool(row[0])}

@app.get("/logs", response_class=PlainTextResponse)
def view_logs(lines:int=1000):
    try:
        with open(LOG_FILE,"r",encoding="utf-8") as f:
            return PlainTextResponse("".join(f.readlines()[-lines:]))
    except FileNotFoundError: raise HTTPException(404,"log missing")

# ─── Comparison & analysis JSON endpoints ────────────────────────────────────
@app.get("/runs/{run_id}/per_second_json")
def per_second_json(run_id:str):
    meta = _load_run_meta(run_id)
    df   = _load_run_df_by_meta(meta)
    sec_iso,p50s,p95s,p99s=_per_second_quantiles(df)
    return {"run_id":run_id,"sec":sec_iso,"p50":p50s,"p95":p95s,"p99":p99s}

@app.get("/runs/{run_id}/summary_json")
def summary_json(run_id:str):
    meta = _load_run_meta(run_id)
    df   = _load_run_df_by_meta(meta)
    s    = _summary_stats(df["latency_ns"])
    s.update({"run_id":run_id,"created_at":meta["created_at"],"approved":bool(meta["approved"])})
    return s

@app.get("/runs/{run_id}/cdf_json")
def cdf_json(run_id:str, points:int=300):
    points = max(50, min(int(points), 2000))
    meta = _load_run_meta(run_id)
    df   = _load_run_df_by_meta(meta)
    lat  = pd.to_numeric(df["latency_ns"], errors="coerce").dropna()
    if lat.empty:
        return {"run_id":run_id,"p":[],"q_ns":[]}
    ps   = [(i+1)/(points+1) for i in range(points)]
    qs   = lat.quantile(ps).astype(float).tolist()
    return {"run_id":run_id,"p":ps,"q_ns":qs}

@app.get("/runs/{run_id}/compare")
def compare_runs(run_id:str, baseline_id:str):
    base_meta = _load_run_meta(baseline_id)
    cur_meta  = _load_run_meta(run_id)
    base_df   = _load_run_df_by_meta(base_meta)
    cur_df    = _load_run_df_by_meta(cur_meta)
    base = _summary_stats(base_df["latency_ns"])
    cur  = _summary_stats(cur_df["latency_ns"])

    def diff(a:float,b:float):
        if b == 0:
            return {"abs": a-b, "pct": None}
        return {"abs": a-b, "pct": (a-b)/b*100.0}

    metrics = ["p50","p95","p99","p999","stdev","madn","iqr","mean","outlier_rate","count"]
    delta = {m: diff(cur.get(m,0.0), base.get(m,0.0)) for m in metrics}
    return {"run_id":run_id, "baseline_id":baseline_id,
            "current":cur, "baseline":base, "delta":delta}













{% extends 'base.html' %}{% block title %}Run {{ id }}{% endblock %}
{% block content %}
<a class="btn btn-link mb-3" href="/">← Back</a>
<h3>Run {{ id }}</h3><p class="text-muted">{{ created_at[:19] }} UTC</p>

<!-- Plots -->
<div id="rawplot" style="height:350px;"></div>
<div id="quantplot" style="height:350px;" class="mt-5"></div>
<div id="cdfplot" style="height:350px;" class="mt-5"></div>

<!-- Approval-critical quick chips (original ones preserved) -->
<div class="row g-3 mt-3">
  <div class="col-auto"><span class="badge bg-secondary" data-bs-toggle="tooltip"
        title="50 % of latencies are below this value (median)">P50</span>
        {{ '%.0f'|format(p50) }} ns</div>
  <div class="col-auto"><span class="badge bg-secondary" data-bs-toggle="tooltip"
        title="95th percentile latency">P95</span>
        {{ '%.0f'|format(p95) }} ns</div>
  <div class="col-auto"><span class="badge bg-secondary" data-bs-toggle="tooltip"
        title="99th percentile latency">P99</span>
        {{ '%.0f'|format(p99) }} ns</div>
  <div class="col-auto"><span class="badge bg-secondary" data-bs-toggle="tooltip"
        title="Population standard deviation">σ</span>
        {{ '%.0f'|format(stdev) }} ns</div>
  <div class="col-auto"><span class="badge bg-secondary" data-bs-toggle="tooltip"
        title="Total samples">n</span> {{ count }}</div>
</div>

<!-- Baseline compare -->
<div class="card mt-4">
  <div class="card-body">
    <div class="row g-3 align-items-center">
      <div class="col-auto">
        <label for="baselineSelect" class="col-form-label">Compare to (baseline):</label>
      </div>
      <div class="col-auto">
        <select id="baselineSelect" class="form-select form-select-sm" style="min-width: 360px;">
          <option value="" {% if not baseline_default %}selected{% endif %}>— none —</option>
          {% for r in baseline_runs %}
            <option value="{{ r.id }}" {% if baseline_default and r.id == baseline_default %}selected{% endif %}>
              {{ r.id }}  •  {{ r.created_at[:19] }} UTC{% if r.approved %} ✓{% endif %}
            </option>
          {% endfor %}
        </select>
      </div>
      <div class="col-auto form-check">
        <input class="form-check-input" type="checkbox" id="toggleBaselineQuant" checked aria-label="Overlay baseline on per-second quantiles">
        <label class="form-check-label" for="toggleBaselineQuant">Overlay baseline on per-second quantiles</label>
      </div>
      <div class="col-auto form-check">
        <input class="form-check-input" type="checkbox" id="toggleBaselineCDF" checked aria-label="Overlay baseline on CDF">
        <label class="form-check-label" for="toggleBaselineCDF">Overlay baseline on CDF</label>
      </div>
    </div>
  </div>
  <div class="table-responsive">
    <table class="table table-sm mb-0" id="compare-table">
      <thead class="table-light">
        <tr><th>Metric</th><th>Current</th><th>Baseline</th><th>Δ</th><th>Δ%</th></tr>
      </thead>
      <tbody></tbody>
    </table>
  </div>
</div>

<!-- Current-run stats with explanations -->
<div class="card mt-4">
  <div class="card-body">
    <h6 class="mb-3">Current run — robust stats</h6>
    <div class="row row-cols-2 row-cols-md-3 row-cols-lg-4 g-3" id="current-stats"></div>
    <details class="mt-3">
      <summary class="small text-muted">What do these mean?</summary>
      <ul class="small mb-0">
        <li><b>P99.9</b>: 99.9th percentile latency (captures ultra-tail).</li>
        <li><b>MAD<span style="font-size:0.9em;vertical-align:super;">n</span></b>: robust σ ≈ 1.4826×MAD; less sensitive to outliers than standard deviation.</li>
        <li><b>IQR</b>: Interquartile range (75th–25th percentile); dispersion of the bulk.</li>
        <li><b>Outlier rate</b>: Share of samples with robust z-score &gt; 3.5 (Hampel filter proxy).</li>
      </ul>
    </details>
  </div>
</div>

<script>
// Raw per-message plot
Plotly.newPlot('rawplot', [{x:{{ x_json|safe }}, y:{{ y_json|safe }},
  mode:'lines', line:{width:1}}], {
  title:'Latency per message',
  margin:{l:40,r:20,t:40,b:40},
  xaxis:{title:'Ingress time', type:'date'},
  yaxis:{title:'Latency (ns)'}
});

// Per-second quantiles (current)
Plotly.newPlot('quantplot', [
  {x:{{ sec_json|safe }}, y:{{ p50_json|safe }}, name:'P50', mode:'lines'},
  {x:{{ sec_json|safe }}, y:{{ p95_json|safe }}, name:'P95', mode:'lines'},
  {x:{{ sec_json|safe }}, y:{{ p99_json|safe }}, name:'P99', mode:'lines'}
], {
  title:'Per-second quantiles',
  margin:{l:40,r:20,t:40,b:40},
  xaxis:{title:'Time (1-s buckets)', type:'date'},
  yaxis:{title:'Latency (ns)'}
});

// Precomputed CDF for current run
const CURRENT_CDF = { p: {{ cdf_p_json|safe }}, q_ns: {{ cdf_q_json|safe }}, run_id: "{{ id }}" };

// Formatters
const fmtInt = (v)=> (v===null||v===undefined) ? '–' : Math.round(v).toLocaleString('en');
const fmtNs  = (v)=> (v===null||v===undefined) ? '–' : Math.round(v).toLocaleString('en') + ' ns';
const fmtPct = (v)=> (v===null||v===undefined) ? '–' : v.toFixed(2) + ' %';

// Render current CDF immediately
(function renderCurrentCDF(){
  const data = [{
    x: CURRENT_CDF.q_ns, y: CURRENT_CDF.p.map(p=>p*100),
    name: `${CURRENT_CDF.run_id}`, mode:'lines'
  }];
  Plotly.newPlot('cdfplot', data, {
    title:'Latency distribution (CDF)',
    margin:{l:40,r:20,t:40,b:40},
    xaxis:{title:'Latency (ns)'},
    yaxis:{title:'Cumulative (%)', range:[0,100]}
  });
})();

// Current-run robust stats
(function renderCurrentStats(){
  const s = {{ stats_json|safe }};
  const items = [
    {k:'p999',lbl:'P99.9',fmt:fmtNs, tip:'99.9th percentile'},
    {k:'madn',lbl:'MAD\u2099',fmt:fmtNs, tip:'Robust σ ≈ 1.4826×MAD'},
    {k:'iqr', lbl:'IQR',  fmt:fmtNs, tip:'75th–25th percentile'},
    {k:'outlier_rate',lbl:'Outlier rate',fmt:(v)=>fmtPct(v*100), tip:'Robust z > 3.5'},
    {k:'mean',lbl:'Mean',fmt:fmtNs, tip:'Arithmetic mean'},
    {k:'stdev',lbl:'σ',fmt:fmtNs, tip:'Population standard deviation'},
    {k:'min',lbl:'Min',fmt:fmtNs, tip:'Minimum latency'},
    {k:'max',lbl:'Max',fmt:fmtNs, tip:'Maximum latency'},
  ];
  const box = document.getElementById('current-stats');
  items.forEach(it=>{
    const v = s[it.k]; const val = it.fmt(v);
    const div = document.createElement('div');
    div.innerHTML = `
      <div class="border rounded p-2 h-100" data-bs-toggle="tooltip" title="${it.tip}">
        <div class="text-muted small">${it.lbl}</div>
        <div class="fw-semibold">${val}</div>
      </div>`;
    box.appendChild(div);
  });
  if (window.bootstrap){
    [...document.querySelectorAll('[data-bs-toggle="tooltip"]')]
      .forEach(el=>new bootstrap.Tooltip(el));
  }
})();

// Baseline comparison
(function(){
  let baselineCDF=null, baselineQuant=null;
  let quantBaselineTraceIdx = [];

  function clearQuantBaseline(){
    if (quantBaselineTraceIdx.length){
      Plotly.deleteTraces('quantplot', quantBaselineTraceIdx);
      quantBaselineTraceIdx = [];
    }
  }

  function maybeOverlayQuantBaseline(){
    clearQuantBaseline();
    if (!baselineQuant) return;
    if (!document.getElementById('toggleBaselineQuant').checked) return;
    const traces = [
      {x:baselineQuant.sec, y:baselineQuant.p50, name:'P50 (baseline)', mode:'lines', line:{dash:'dot'}},
      {x:baselineQuant.sec, y:baselineQuant.p95, name:'P95 (baseline)', mode:'lines', line:{dash:'dot'}},
      {x:baselineQuant.sec, y:baselineQuant.p99, name:'P99 (baseline)', mode:'lines', line:{dash:'dot'}}
    ];
    Plotly.addTraces('quantplot', traces).then(idxs => { quantBaselineTraceIdx = idxs; });
  }

  function renderCDF(){
    const showBaseline = document.getElementById('toggleBaselineCDF').checked;
    const data = [{
      x: CURRENT_CDF.q_ns, y: CURRENT_CDF.p.map(p=>p*100),
      name: `${CURRENT_CDF.run_id}`, mode:'lines'
    }];
    if (baselineCDF && showBaseline){
      data.push({
        x: baselineCDF.q_ns, y: baselineCDF.p.map(p=>p*100),
        name: `${baselineCDF.run_id} (baseline)`, mode:'lines', line:{dash:'dot'}
      });
    }
    Plotly.react('cdfplot', data, {
      title:'Latency distribution (CDF)',
      margin:{l:40,r:20,t:40,b:40},
      xaxis:{title:'Latency (ns)'},
      yaxis:{title:'Cumulative (%)', range:[0,100]}
    });
  }

  function paintDeltaCell(td, metricKey, cur, base){
    const lowerIsBetter = new Set(['p50','p95','p99','p999','stdev','madn','iqr','mean','outlier_rate']);
    const direction = (cur - base);
    const improved = lowerIsBetter.has(metricKey) ? (direction < 0) : (direction > 0);
    td.classList.remove('text-success','text-danger');
    if (direction === 0 || isNaN(direction)) return;
    td.classList.add(improved ? 'text-success' : 'text-danger');
  }

  async function updateCompareTable(){
    const tbody = document.querySelector('#compare-table tbody');
    tbody.innerHTML = '';
    const baselineId = document.getElementById('baselineSelect').value;
    if (!baselineId){ return; }
    const cmp = await (await fetch(`/runs/{{ id }}/compare?baseline_id=${baselineId}`)).json();
    const rows = [
      {k:'p50', lbl:'P50', fmt:fmtNs},
      {k:'p95', lbl:'P95', fmt:fmtNs},
      {k:'p99', lbl:'P99', fmt:fmtNs},
      {k:'p999',lbl:'P99.9', fmt:fmtNs},
      {k:'mean',lbl:'Mean', fmt:fmtNs},
      {k:'stdev',lbl:'σ', fmt:fmtNs},
      {k:'madn',lbl:'MAD\u2099 (robust σ)', fmt:fmtNs},
      {k:'iqr', lbl:'IQR', fmt:fmtNs},
      {k:'outlier_rate', lbl:'Outlier rate', fmt:(v)=>fmtPct(v*100)},
      {k:'count',lbl:'n', fmt:(v)=>fmtInt(v)}
    ];
    rows.forEach(r=>{
      const tr = document.createElement('tr');
      const cur = cmp.current[r.k]; const base = cmp.baseline[r.k];
      const deltaAbs = (cur!=null && base!=null) ? (cur - base) : null;
      const deltaPct = (cmp.delta[r.k] && cmp.delta[r.k].pct!=null) ? cmp.delta[r.k].pct : null;
      tr.innerHTML = `<td>${r.lbl}</td>
                      <td>${r.fmt(cur)}</td>
                      <td>${r.fmt(base)}</td>
                      <td>${r.fmt(deltaAbs)}</td>
                      <td>${deltaPct==null?'–':deltaPct.toFixed(2)+' %'}</td>`;
      tbody.appendChild(tr);
      paintDeltaCell(tr.children[3], r.k, cur, base);
      paintDeltaCell(tr.children[4], r.k, cur, base);
    });
  }

  async function loadBaseline(id){
    if (!id){
      baselineQuant = null; baselineCDF = null;
      clearQuantBaseline(); renderCDF(); updateCompareTable();
      return;
    }
    const [q, c] = await Promise.all([
      fetch(`/runs/${id}/per_second_json`).then(r=>r.json()),
      fetch(`/runs/${id}/cdf_json?points=300`).then(r=>r.json()),
    ]);
    baselineQuant = q; baselineCDF = c;
    maybeOverlayQuantBaseline();
    renderCDF();
    updateCompareTable();
  }

  // Wire UI
  document.getElementById('toggleBaselineQuant').addEventListener('change', ()=> {
    maybeOverlayQuantBaseline();
  });
  document.getElementById('toggleBaselineCDF').addEventListener('change', ()=> {
    renderCDF();
  });
  document.getElementById('baselineSelect').addEventListener('change', (e)=> loadBaseline(e.target.value));

  // Auto-load default baseline if present
  (function initAutoBaseline(){
    const sel = document.getElementById('baselineSelect');
    if (sel && sel.value){ loadBaseline(sel.value); }
  })();
})();
</script>

{% if approved %}
  <div class="alert alert-success mt-4 d-flex justify-content-between">
    <span>Approved by <b>{{ approved_by }}</b> at {{ approved_at[:19] }} UTC</span>
    <form action="/runs/{{ id }}/unapprove" method="post">
      <button class="btn btn-outline-danger btn-sm" data-bs-toggle="tooltip"
              title="Mark this run as not approved">Un-approve</button>
    </form>
  </div>
{% else %}
  <form class="mt-4" action="/runs/{{ id }}/approve" method="post">
    <div class="input-group w-auto">
      <input class="form-control form-control-sm" name="user" placeholder="Your name">
      <button class="btn btn-success btn-sm">Approve</button>
    </div>
  </form>
{% endif %}
{% endblock %}



